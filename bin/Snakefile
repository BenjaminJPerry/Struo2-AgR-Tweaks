def all_which_input(wildcards):
    """
    The final output files for both db_create & db_update
    """
    input_files = []
    
    # kraken2
    if not skipped(config['databases']['kraken2']):
        input_files.append(os.path.join(kraken2_dir, 'hash.k2d'))
        input_files.append(os.path.join(kraken2_dir, 'opts.k2d'))
        input_files.append(os.path.join(kraken2_dir, 'taxo.k2d'))
        input_files.append(os.path.join(kraken2_dir, 'seqid2taxid.map'))
        # bracken
        if not skipped(config['databases']['bracken']):
    	    x = expand(os.path.join(kraken2_dir, 'database{read_len}mers.kraken'),
	               read_len = config['params']['bracken']['build_read_lens'])
            input_files += x
    # genes
    if not skipped(config['databases']['genes']):
        input_files.append(genes_dir + 'genome_reps_filtered.fna.gz')
        input_files.append(genes_dir + 'genome_reps_filtered.faa.gz')
        input_files.append(genes_dir + 'genome_reps_filtered.txt.gz')
        if str(config['keep_intermediate']) == 'True':
            # mmseqs gene database
            input_files.append(genes_dir + 'genes_db.tar.gz')
            ## mmseqs cluster database
            input_files.append(genes_dir + 'cluster/clusters_db.tar.gz')
            ## cluster membership info
            input_files.append(genes_dir + 'cluster/clusters_membership.tsv.gz')
            ## cluster rep sequences
            input_files.append(genes_dir + 'cluster/clusters_reps.faa.gz')
                                    
    # humann3
    ## humann3 intermediate files
    if (not skipped(config['databases']['humann3_bowtie2']) and
        not skipped(config['databases']['humann3_diamond'])):
        # annotation hits
        input_files.append(humann3_dir + 'annotation_hits.gz')
        ## annotated genes (all)
        input_files.append(humann3_dir + 'filtered_reps_annot.fna.gz')
        input_files.append(humann3_dir + 'filtered_reps_annot.faa.gz')
        input_files.append(humann3_dir + 'filtered_reps_annot.tsv.gz')
    ## databases
    if not skipped(config['databases']['humann3_bowtie2']):
        input_files.append(os.path.join(humann3_dir, 'bowtie2_build.done'))
    if not skipped(config['databases']['humann3_diamond']):
        input_files.append(os.path.join(humann3_dir, 'protein_database',
                                        config['dmnd_name']))
    
    # ret
    return input_files



# def all_which_input(wildcards):
#     input_files = []
    
#     # kraken2
#     if not skipped(config['databases']['kraken2']):
#         if str(config['params']['bracken']['keep_intermediate']) == 'True':
#             x = expand(kraken2_dir + 'added/{sample}.done',
#                        sample = config['samples_unique'])
#             input_files += x
#         input_files.append(os.path.join(kraken2_dir, 'hash.k2d'))
#         input_files.append(os.path.join(kraken2_dir, 'opts.k2d'))
#         input_files.append(os.path.join(kraken2_dir, 'taxo.k2d'))
#         input_files.append(os.path.join(kraken2_dir, 'seqid2taxid.map'))

#         # bracken
#         if not skipped(config['databases']['bracken']):
#     	    x = expand(os.path.join(kraken2_dir, 'database{read_len}mers.kraken'),
# 	               read_len = config['params']['bracken']['build_read_lens'])
#             input_files += x
            
#     # humann3
#     if not skipped(config['databases']['humann3_bowtie2']):
#         input_files.append(os.path.join(humann3_dir, 'bowtie2_build.done'))
#     if not skipped(config['databases']['humann3_diamond']):
#         input_files.append(os.path.join(humann3_dir, 'protein_database',
#                                         config['dmnd_name']))
#     ## humann3 intermediate files
#     if (not skipped(config['databases']['humann3_bowtie2']) and
#         not skipped(config['databases']['humann3_diamond'])):
#         if str(config['params']['genes']['keep_gene_info']) == 'True':
#             input_files.append(genes_dir + 'genome_reps_filtered.fna.gz')
#             input_files.append(genes_dir + 'genome_reps_filtered.faa.gz')
#             input_files.append(genes_dir + 'genome_reps_filtered.txt.gz')
#         if str(config['params']['genes']['keep_cluster_db']) == 'True':
#             input_files.append(genes_dir + 'cluster/genes_db')
#             input_files.append(genes_dir + 'cluster/genes_db.dbtype')
#             input_files.append(genes_dir + 'cluster/genes_db.index')
#             input_files.append(genes_dir + 'cluster/genes_db.lookup')
#             input_files.append(genes_dir + 'cluster/genes_db.source')
#             input_files.append(genes_dir + 'cluster/genes_db_h')
#             input_files.append(genes_dir + 'cluster/genes_db_h.dbtype')
#             input_files.append(genes_dir + 'cluster/genes_db_h.index')
#             input_files += expand(genes_dir + 'cluster/clusters_db.{X}',
#                                   X = range(12))
#             input_files.append(genes_dir + 'cluster/clusters_db.dbtype')
#             input_files.append(genes_dir + 'cluster/clusters_db.index')
#             input_files.append(genes_dir + 'cluster/clusters_db_h')            
#         if str(config['params']['genes']['keep_annot_genes']) == 'True':
#             input_files.append(humann3_dir + 'filtered_reps_annot.fna.gz')
#             input_files.append(humann3_dir + 'filtered_reps_annot.faa.gz')
#             input_files.append(humann3_dir + 'filtered_reps_annot.tsv.gz')
                    
#     # ret
#     return input_files

# # onsuccess/error
# ## funcs
# def write_config(out_file):
#     out_dir = os.path.split(out_file)[0]
#     if not os.path.isdir(out_dir):
#         os.makedirs(out_dir)
#     config_tmp = {k:(v.to_string(max_rows=1, max_cols=10) if isinstance(v, pd.DataFrame) else v) \
#                   for k,v in config.items()}
#     with open(out_file, 'w') as outF:
#         json.dump(config_tmp, outF, indent=4)

# def file_atch(file_path, file_type):
#    if os.path.isfile(file_path) and os.stat(file_path).st_size > 0:
#        attach = '-a {}'.format(file_path)   
#        file_path = os.path.split(file_path)[1]
#        msg = 'See attached {} file: {}'.format(file_type, file_path)
#    else:
#        attach = ''
#        file_path = os.path.split(file_path)[1]
#        msg = 'WARNING: could not attach {}: {}'.format(file_type, file_path)
#    return attach,msg
       
# def send_email(rpt_file, email, config, pipeline='LL_pipeline', success=True):
#     if find_executable('mutt') is None:
#         print('WARNING: `mutt` not found. Not sending an email')
# 	return 0

#     # json of config
#     config_json = os.path.join(config['tmp_dir'], 'job_config.json')
#     write_config(config_json)
    
#     # email
#     title = '{} finished successfully' if success is True else '{} => error occurred'
#     title = title.format(pipeline)
#     rpt_atch,rpt_msg = file_atch(rpt_file, 'job report')
#     cfg_atch,cfg_msg = file_atch(config_json, 'pipeline config')    
#     body = '\n'.join([rpt_msg, cfg_msg,
#                       'Snakemake pipeline location: {}'.format(workflow.basedir)])
#     cmd = "echo '{body}' | mutt {attch1} {attch2} -s '{title}' -- {email}"
#     cmd = cmd.format(body=body, attch1=rpt_atch, attch2=cfg_atch, title=title, email=email)
#     try:
#         shell(cmd)
#     except subprocess.CalledProcessError as e:
#         cmd = "echo '{body}' | mutt {attch2} -s '{title}' -- {email}"
#         cmd = cmd.format(body=body, attch2=cfg_atch, title=title, email=email)
#         shell(cmd)
    
#     # cleanup
#     os.remove(rpt_file)
#     os.remove(config_json)

# def mk_cmd(success=True):
#     msg = 'complete' if success is True else 'error'
#     print('Pipeline {}! Creating report...'.format(msg))
#     exe = os.path.join(config['pipeline']['script_folder'], 'log_summarize.py')
#     rpt_file = os.path.join(config['tmp_dir'], 'job_report.csv')
#     cmd = '{exe} {{log}} > {rpt_file}'.format(exe=exe, rpt_file=rpt_file)
#     return rpt_file, cmd


# ## call
# onsuccess:
#     rpt_file,cmd = mk_cmd(success=True)
#     try:
#         shell(cmd)
#     except subprocess.CalledProcessError:
#         print('WARNING: could not parse snakemake log file')
#     send_email(rpt_file, config['pipeline']['email'], config, pipeline='Struo2', success=True)

# onerror:
#     rpt_file,cmd = mk_cmd(success=False)
#     try:
#         shell(cmd)
#     except subprocess.CalledProcessError:
#         print('WARNING: could not parse snakemake log file')
#     send_email(rpt_file, config['pipeline']['email'], config, pipeline='Struo2', success=False)
 
